{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0eadaf-8f49-4d65-b0eb-4d97df6eb2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Full-period descriptive summary (daily $10 contributions) ===\n",
      "days_traded: 5463\n",
      "period_start: 1996-10-15 00:00:00\n",
      "period_end: 2018-06-28 00:00:00\n",
      "final_wealth_bh: 115533.91818780858\n",
      "final_wealth_ls: 32137.25750646982\n",
      "contrib_multiple_bh: 2.1148438255136113\n",
      "contrib_multiple_ls: 0.5882712338727772\n",
      "sharpe_bh_approx: 0.42267102425628184\n",
      "sharpe_ls_approx: -0.41412583306405076\n",
      "max_drawdown_bh: -0.513651333143571\n",
      "max_drawdown_ls: -0.40356450728832544\n",
      "xirr_bh: 0.06412003001568187\n",
      "xirr_ls: 5.0\n",
      "\n",
      "Computed 4267 rolling 5-year windows -> rolling_5y_metrics.csv\n",
      "\n",
      "=== 5-year block bootstrap MC summary ===\n",
      "P(LS beats BH over a random 5y block): 0.144\n",
      "Median LS/BH: 0.711\n",
      "Median (LS - BH) wealth: -3879.97\n",
      "5th/95th pct (LS - BH): -6842.39 / 6460.09\n",
      "\n",
      "Outputs written:\n",
      "- oos_daily_returns.csv\n",
      "- wealth_paths_full_period.csv\n",
      "- rolling_5y_metrics.csv\n",
      "- mc_5y_block_bootstrap.csv\n",
      "- summary_full_period.txt\n",
      "- figure_wealth_paths.png\n",
      "- figure_mc5_final_wealth.png\n",
      "- figure_mc5_ls_minus_bh.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Walk-Forward LSTM Long/Short vs Daily $10 Buy&Hold (SPX)\n",
    "# + Rolling 5Y Windows + 5Y Block Bootstrap Monte Carlo\n",
    "# Cleaned + No Lookahead + Low-noise execution\n",
    "# ============================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Reduce TensorFlow log noise BEFORE importing TF ---\n",
    "os.environ.setdefault(\"TF_CPP_MIN_LOG_LEVEL\", \"2\")  # 0=all, 1=INFO, 2=WARNING, 3=ERROR\n",
    "\n",
    "# --- Filter common warnings (keeps tracebacks for real errors) ---\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Reproducibility (best-effort)\n",
    "# ============================================================\n",
    "def set_seeds(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Data loading (CSV/XLS/XLSX)\n",
    "# ============================================================\n",
    "def load_price_file(path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a price file and returns a DataFrame with columns:\n",
    "      Date (datetime64[ns]) and Close (float)\n",
    "    Supports .csv, .xls, .xlsx.\n",
    "\n",
    "    Tries common column name variations (case/space-insensitive).\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path.resolve()}\")\n",
    "\n",
    "    suffix = path.suffix.lower()\n",
    "\n",
    "    if suffix == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "    elif suffix in {\".xls\", \".xlsx\"}:\n",
    "        # For .xls, xlrd is typically required; for .xlsx, openpyxl is typical.\n",
    "        # Pandas will pick an engine if available; we supply common ones as fallback.\n",
    "        try:\n",
    "            df = pd.read_excel(path, engine=\"xlrd\" if suffix == \".xls\" else \"openpyxl\")\n",
    "        except Exception:\n",
    "            df = pd.read_excel(path)  # fallback (lets pandas choose)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {suffix}\")\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.lower()\n",
    "    )\n",
    "\n",
    "    # Identify date column\n",
    "    date_candidates = [\"date\", \"datetime\", \"timestamp\"]\n",
    "    date_col = next((c for c in df.columns if c in date_candidates), None)\n",
    "    if date_col is None:\n",
    "        # If no date column exists, create a synthetic index-based one\n",
    "        df[\"date\"] = pd.RangeIndex(len(df))\n",
    "        date_col = \"date\"\n",
    "\n",
    "    # Identify close column\n",
    "    close_candidates = [\"close\", \"adj close\", \"adj_close\", \"price\", \"close price\"]\n",
    "    close_col = next((c for c in df.columns if c in close_candidates), None)\n",
    "    if close_col is None:\n",
    "        # fallback to first numeric column\n",
    "        num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "        if not num_cols:\n",
    "            raise ValueError(\"No numeric price column found.\")\n",
    "        close_col = num_cols[0]\n",
    "\n",
    "    out = df[[date_col, close_col]].copy()\n",
    "    out.rename(columns={date_col: \"Date\", close_col: \"Close\"}, inplace=True)\n",
    "\n",
    "    # Parse Date if not numeric range index\n",
    "    if out[\"Date\"].dtype != \"int64\" and out[\"Date\"].dtype != \"float64\":\n",
    "        out[\"Date\"] = pd.to_datetime(out[\"Date\"], errors=\"coerce\")\n",
    "        out = out.dropna(subset=[\"Date\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    out[\"Close\"] = pd.to_numeric(out[\"Close\"], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"Close\"]).reset_index(drop=True)\n",
    "\n",
    "    if len(out) < 500:\n",
    "        raise ValueError(\"Not enough rows after cleaning. Need a reasonable history.\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Feature engineering (close-only)\n",
    "# ============================================================\n",
    "def features_from_close(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Returns\n",
    "    df[\"ret_1d\"] = df[\"Close\"].pct_change()\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        df[\"log_ret_1d\"] = np.log(df[\"Close\"]).diff()\n",
    "\n",
    "    # Multi-horizon returns + rolling vol\n",
    "    for w in (5, 10, 20, 60):\n",
    "        df[f\"ret_{w}d\"] = df[\"Close\"].pct_change(w)\n",
    "        df[f\"vol_{w}\"] = df[\"ret_1d\"].rolling(w).std()\n",
    "\n",
    "    # SMAs + slopes\n",
    "    for w in (5, 10, 20, 50, 200):\n",
    "        sma = df[\"Close\"].rolling(w).mean()\n",
    "        df[f\"sma_{w}\"] = sma\n",
    "        df[f\"sma_slope_{w}\"] = sma.diff()\n",
    "\n",
    "    # EMA/MACD\n",
    "    ema12 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    macd = ema12 - ema26\n",
    "    macd_sig = macd.ewm(span=9, adjust=False).mean()\n",
    "    df[\"ema_12\"] = ema12\n",
    "    df[\"ema_26\"] = ema26\n",
    "    df[\"macd\"] = macd\n",
    "    df[\"macd_signal\"] = macd_sig\n",
    "\n",
    "    # RSI(14)\n",
    "    delta = df[\"Close\"].diff()\n",
    "    up = np.where(delta > 0, delta, 0.0)\n",
    "    down = np.where(delta < 0, -delta, 0.0)\n",
    "    roll_up = pd.Series(up, index=df.index).rolling(14).mean()\n",
    "    roll_down = pd.Series(down, index=df.index).rolling(14).mean()\n",
    "    rs = roll_up / (roll_down + 1e-12)\n",
    "    df[\"rsi_14\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # Bollinger %b-ish scaled\n",
    "    bb_w = 20\n",
    "    bb_ma = df[\"Close\"].rolling(bb_w).mean()\n",
    "    bb_std = df[\"Close\"].rolling(bb_w).std()\n",
    "    df[\"bb_perc_b\"] = (df[\"Close\"] - bb_ma) / (2 * (bb_std + 1e-12))\n",
    "\n",
    "    # Z-scores\n",
    "    for w in (20, 60):\n",
    "        mu = df[\"Close\"].rolling(w).mean()\n",
    "        sd = df[\"Close\"].rolling(w).std()\n",
    "        df[f\"close_z_{w}\"] = (df[\"Close\"] - mu) / (sd + 1e-12)\n",
    "\n",
    "    # ROC\n",
    "    for w in (5, 10, 20):\n",
    "        df[f\"roc_{w}\"] = df[\"Close\"].pct_change(w)\n",
    "\n",
    "    # Calendar features (if Date is datetime)\n",
    "    if np.issubdtype(df[\"Date\"].dtype, np.datetime64):\n",
    "        d = df[\"Date\"]\n",
    "        df[\"dow\"] = d.dt.dayofweek\n",
    "        df[\"dom\"] = d.dt.day\n",
    "        df[\"month\"] = d.dt.month\n",
    "        df[\"is_month_end\"] = d.dt.is_month_end.astype(int)\n",
    "        df[\"is_quarter_end\"] = d.dt.is_quarter_end.astype(int)\n",
    "        df[\"is_year_end\"] = d.dt.is_year_end.astype(int)\n",
    "\n",
    "    # Target: next-day return (t -> t+1)\n",
    "    df[\"target_ret_1d\"] = df[\"ret_1d\"].shift(-1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_regimes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Simple regime encodings\n",
    "    trend_score = df[\"sma_slope_50\"].rolling(10).mean() / (df[\"Close\"].rolling(50).std() + 1e-12)\n",
    "    df[\"trend_score\"] = trend_score\n",
    "\n",
    "    trend_cond = (trend_score > 0.05) & (df[\"macd\"] > df[\"macd_signal\"])\n",
    "    mr_cond = (df[\"rsi_14\"] < 30) | (df[\"rsi_14\"] > 70)\n",
    "\n",
    "    df[\"regime\"] = np.select(\n",
    "        [trend_cond, mr_cond],\n",
    "        [\"trend\", \"mean_reversion\"],\n",
    "        default=\"neutral\",\n",
    "    )\n",
    "\n",
    "    df = pd.get_dummies(df, columns=[\"regime\"], prefix=\"reg\", dtype=int)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Sequence builder (aligned, fast)\n",
    "# ============================================================\n",
    "def build_sequences_aligned(X: np.ndarray, y: np.ndarray, lookback: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    For each t >= lookback-1:\n",
    "      X_seq = X[t-lookback+1 : t+1]\n",
    "      y_seq = y[t]\n",
    "    \"\"\"\n",
    "    if lookback < 2:\n",
    "        raise ValueError(\"lookback must be >= 2\")\n",
    "\n",
    "    n = len(X)\n",
    "    if n < lookback:\n",
    "        return np.empty((0, lookback, X.shape[1])), np.empty((0,))\n",
    "\n",
    "    # sliding windows along first axis\n",
    "    try:\n",
    "        from numpy.lib.stride_tricks import sliding_window_view\n",
    "        Xw = sliding_window_view(X, window_shape=(lookback, X.shape[1]))[:, 0, :, :]\n",
    "        yw = y[lookback - 1 :]\n",
    "        return Xw.astype(np.float32), yw.astype(np.float32)\n",
    "    except Exception:\n",
    "        # fallback loop (still correct)\n",
    "        X_seq = []\n",
    "        y_seq = []\n",
    "        for t in range(lookback - 1, n):\n",
    "            X_seq.append(X[t - lookback + 1 : t + 1])\n",
    "            y_seq.append(y[t])\n",
    "        return np.asarray(X_seq, dtype=np.float32), np.asarray(y_seq, dtype=np.float32)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Model builder\n",
    "# ============================================================\n",
    "def build_model(input_shape: tuple[int, int], seed: int = 42) -> tf.keras.Model:\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Input(shape=input_shape),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(32),\n",
    "            Dropout(0.2),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Walk-forward backtest (NO LOOKAHEAD)\n",
    "# ============================================================\n",
    "@dataclass(frozen=True)\n",
    "class WalkForwardConfig:\n",
    "    lookback: int = 60\n",
    "    initial_train_years: int = 10\n",
    "    retrain_every_days: int = 252 * 5\n",
    "    epochs: int = 8\n",
    "    batch_size: int = 256\n",
    "    patience: int = 3\n",
    "    val_frac: float = 0.2\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "def walk_forward_oos_returns(\n",
    "    price_df: pd.DataFrame,\n",
    "    cfg: WalkForwardConfig,\n",
    "    transaction_cost_bps: float = 3,\n",
    "    slippage_bps: float = 2,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Output columns:\n",
    "      Date, spx_ret_next, pred_next, signal, strategy_ret\n",
    "    Returns correspond to next-day close-to-close (t -> t+1).\n",
    "    \"\"\"\n",
    "\n",
    "    feat = add_regimes(features_from_close(price_df)).dropna().reset_index(drop=True)\n",
    "\n",
    "    # Feature/target split\n",
    "    exclude = {\"Date\", \"target_ret_1d\"}\n",
    "    X_cols = [c for c in feat.columns if c not in exclude]\n",
    "    X_raw = feat[X_cols].to_numpy(dtype=float)\n",
    "    y = feat[\"target_ret_1d\"].to_numpy(dtype=float)  # return t->t+1\n",
    "\n",
    "    has_date = np.issubdtype(feat[\"Date\"].dtype, np.datetime64)\n",
    "\n",
    "    # Determine first trade index (t0)\n",
    "    if has_date:\n",
    "        start_date = feat[\"Date\"].iloc[0]\n",
    "        cutoff_date = start_date + pd.DateOffset(years=cfg.initial_train_years)\n",
    "        eligible = feat.index[feat[\"Date\"] < cutoff_date]\n",
    "        if len(eligible) == 0:\n",
    "            raise ValueError(\"Not enough data before initial_train_years cutoff.\")\n",
    "        first_trade_t = int(eligible.max())\n",
    "    else:\n",
    "        first_trade_t = int(cfg.initial_train_years * 252)\n",
    "\n",
    "    # Need enough history for sequences\n",
    "    if first_trade_t < cfg.lookback + 50:\n",
    "        raise ValueError(\n",
    "            f\"Not enough initial history for lookback={cfg.lookback}. \"\n",
    "            \"Reduce lookback or increase initial_train_years / provide more data.\"\n",
    "        )\n",
    "\n",
    "    # Costs\n",
    "    cost = (transaction_cost_bps + slippage_bps) / 10000.0\n",
    "\n",
    "    preds = np.full(len(feat), np.nan, dtype=float)\n",
    "    signals = np.zeros(len(feat), dtype=float)\n",
    "    strat_ret = np.full(len(feat), np.nan, dtype=float)\n",
    "\n",
    "    model: tf.keras.Model | None = None\n",
    "    scaler: StandardScaler | None = None\n",
    "    next_retrain_t = first_trade_t\n",
    "\n",
    "    # IMPORTANT:\n",
    "    # At time t, you do NOT know y[t] yet (it's t->t+1 return).\n",
    "    # So training must use y up to (t-1).\n",
    "    for t in range(first_trade_t, len(feat)):\n",
    "        # retrain periodically using info available up to t (targets up to t-1)\n",
    "        if model is None or t >= next_retrain_t:\n",
    "            train_end = t - 1\n",
    "            if train_end < cfg.lookback:\n",
    "                # not enough target history yet\n",
    "                next_retrain_t = t + 1\n",
    "                continue\n",
    "\n",
    "            X_train_raw = X_raw[: train_end + 1]\n",
    "            y_train = y[: train_end + 1]\n",
    "\n",
    "            scaler = StandardScaler().fit(X_train_raw)\n",
    "            X_train = scaler.transform(X_train_raw)\n",
    "\n",
    "            X_seq, y_seq = build_sequences_aligned(X_train, y_train, cfg.lookback)\n",
    "            if len(X_seq) < 50:\n",
    "                next_retrain_t = t + 1\n",
    "                continue\n",
    "\n",
    "            val_size = max(1, int(len(X_seq) * cfg.val_frac))\n",
    "            if len(X_seq) <= val_size:\n",
    "                val_size = 1\n",
    "\n",
    "            X_tr, y_tr = X_seq[:-val_size], y_seq[:-val_size]\n",
    "            X_val, y_val = X_seq[-val_size:], y_seq[-val_size:]\n",
    "\n",
    "            model = build_model((cfg.lookback, X_seq.shape[-1]), seed=cfg.seed)\n",
    "            es = EarlyStopping(monitor=\"val_loss\", patience=cfg.patience, restore_best_weights=True)\n",
    "\n",
    "            model.fit(\n",
    "                X_tr, y_tr,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=cfg.epochs,\n",
    "                batch_size=cfg.batch_size,\n",
    "                shuffle=False,\n",
    "                verbose=0,\n",
    "                callbacks=[es],\n",
    "            )\n",
    "\n",
    "            next_retrain_t = t + cfg.retrain_every_days\n",
    "\n",
    "        # If we didn't manage to train, skip prediction\n",
    "        if model is None or scaler is None:\n",
    "            continue\n",
    "\n",
    "        # Predict y[t] using features up to t\n",
    "        X_scaled_all = scaler.transform(X_raw)  # scaler fixed until next retrain\n",
    "        X_last = X_scaled_all[t - cfg.lookback + 1 : t + 1].reshape(1, cfg.lookback, -1)\n",
    "\n",
    "        pred = float(model.predict(X_last, verbose=0).ravel()[0])\n",
    "        preds[t] = pred\n",
    "\n",
    "        sig = float(np.sign(pred))  # -1, 0, +1\n",
    "        signals[t] = sig\n",
    "\n",
    "        r_next = float(y[t])  # realized next-day return\n",
    "\n",
    "        prev_sig = float(signals[t - 1]) if t > first_trade_t else 0.0\n",
    "        pos_change = abs(sig - prev_sig)  # 0, 1, or 2\n",
    "\n",
    "        strat_ret[t] = sig * r_next - pos_change * cost\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": feat[\"Date\"] if has_date else pd.RangeIndex(len(feat)),\n",
    "            \"spx_ret_next\": y,\n",
    "            \"pred_next\": preds,\n",
    "            \"signal\": signals,\n",
    "            \"strategy_ret\": strat_ret,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # keep only where we are actually trading AND have strategy returns\n",
    "    out = out.iloc[first_trade_t:].dropna(subset=[\"strategy_ret\"]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) Wealth evolution (daily contributions)\n",
    "# ============================================================\n",
    "def evolve_with_daily_contribution(r: np.ndarray, contrib: float = 10.0, v0: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    V_{t+1} = (V_t + contrib) * (1 + r_t)\n",
    "    \"\"\"\n",
    "    r = np.asarray(r, dtype=float)\n",
    "    V = np.empty(len(r) + 1, dtype=float)\n",
    "    V[0] = float(v0)\n",
    "    for t in range(len(r)):\n",
    "        V[t + 1] = (V[t] + contrib) * (1.0 + r[t])\n",
    "    return V\n",
    "\n",
    "\n",
    "def max_drawdown(wealth: np.ndarray) -> float:\n",
    "    wealth = np.asarray(wealth, dtype=float)\n",
    "    peaks = np.maximum.accumulate(wealth)\n",
    "    dd = (wealth - peaks) / (peaks + 1e-12)\n",
    "    return float(dd.min())\n",
    "\n",
    "\n",
    "def approx_sharpe(daily_r: np.ndarray) -> float:\n",
    "    daily_r = np.asarray(daily_r, dtype=float)\n",
    "    mu = np.nanmean(daily_r)\n",
    "    sd = np.nanstd(daily_r) + 1e-12\n",
    "    return float(np.sqrt(252) * mu / sd)\n",
    "\n",
    "\n",
    "def contribution_multiple(final_wealth: float, contrib: float, n_days: int) -> float:\n",
    "    total = contrib * n_days\n",
    "    return float(final_wealth / (total + 1e-12))\n",
    "\n",
    "\n",
    "def xirr_daily(dates: pd.Series, contrib: float, ending_wealth: float) -> float:\n",
    "    \"\"\"\n",
    "    Money-weighted return (IRR) for daily contributions.\n",
    "    Cashflows: -contrib each day; final +ending_wealth at last date.\n",
    "    \"\"\"\n",
    "    dates = pd.to_datetime(pd.Series(dates)).reset_index(drop=True)\n",
    "\n",
    "    cf_dates = list(dates)\n",
    "    cfs = [-contrib] * len(dates)\n",
    "    cf_dates.append(dates.iloc[-1])\n",
    "    cfs.append(float(ending_wealth))\n",
    "\n",
    "    t0 = cf_dates[0]\n",
    "    yearfrac = np.array([(d - t0).days / 365.25 for d in cf_dates], dtype=float)\n",
    "    cfs = np.array(cfs, dtype=float)\n",
    "\n",
    "    def xnpv(rate: float) -> float:\n",
    "        return float(np.sum(cfs / (1.0 + rate) ** yearfrac))\n",
    "\n",
    "    def dxnpv(rate: float) -> float:\n",
    "        return float(np.sum(-yearfrac * cfs / (1.0 + rate) ** (yearfrac + 1.0)))\n",
    "\n",
    "    r = 0.08\n",
    "    for _ in range(100):\n",
    "        f = xnpv(r)\n",
    "        df = dxnpv(r)\n",
    "        if abs(df) < 1e-12:\n",
    "            break\n",
    "        r_new = r - f / df\n",
    "        r_new = float(np.clip(r_new, -0.95, 5.0))\n",
    "        if abs(r_new - r) < 1e-10:\n",
    "            r = r_new\n",
    "            break\n",
    "        r = r_new\n",
    "    return float(r)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Rolling 5Y windows\n",
    "# ============================================================\n",
    "def rolling_windows_5y(df_ret: pd.DataFrame, block_years: int = 5, contrib: float = 10.0) -> pd.DataFrame:\n",
    "    out = []\n",
    "    dates = df_ret[\"Date\"]\n",
    "    has_date = np.issubdtype(pd.Series(dates).dtype, np.datetime64)\n",
    "\n",
    "    if has_date:\n",
    "        dates = pd.to_datetime(dates).reset_index(drop=True)\n",
    "\n",
    "        for start_i in range(len(df_ret)):\n",
    "            start_date = dates.iloc[start_i]\n",
    "            end_date = start_date + pd.DateOffset(years=block_years)\n",
    "\n",
    "            end_i = int(dates.searchsorted(end_date, side=\"left\") - 1)\n",
    "            if end_i <= start_i:\n",
    "                continue\n",
    "\n",
    "            # avoid truncated tail windows\n",
    "            if (dates.iloc[end_i] - start_date).days < int(365.25 * block_years * 0.95):\n",
    "                continue\n",
    "\n",
    "            r_bh = df_ret[\"spx_ret_next\"].iloc[start_i : end_i + 1].to_numpy()\n",
    "            r_ls = df_ret[\"strategy_ret\"].iloc[start_i : end_i + 1].to_numpy()\n",
    "            d_win = dates.iloc[start_i : end_i + 1]\n",
    "\n",
    "            W_bh = evolve_with_daily_contribution(r_bh, contrib=contrib)\n",
    "            W_ls = evolve_with_daily_contribution(r_ls, contrib=contrib)\n",
    "\n",
    "            out.append(\n",
    "                {\n",
    "                    \"start\": start_date,\n",
    "                    \"end\": dates.iloc[end_i],\n",
    "                    \"days\": int(len(r_bh)),\n",
    "                    \"final_bh\": float(W_bh[-1]),\n",
    "                    \"final_ls\": float(W_ls[-1]),\n",
    "                    \"mult_bh\": contribution_multiple(W_bh[-1], contrib, len(r_bh)),\n",
    "                    \"mult_ls\": contribution_multiple(W_ls[-1], contrib, len(r_ls)),\n",
    "                    \"sharpe_bh\": approx_sharpe(r_bh),\n",
    "                    \"sharpe_ls\": approx_sharpe(r_ls),\n",
    "                    \"mdd_bh\": max_drawdown(W_bh),\n",
    "                    \"mdd_ls\": max_drawdown(W_ls),\n",
    "                    \"xirr_bh\": xirr_daily(d_win, contrib=contrib, ending_wealth=W_bh[-1]),\n",
    "                    \"xirr_ls\": xirr_daily(d_win, contrib=contrib, ending_wealth=W_ls[-1]),\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        L = int(252 * block_years)\n",
    "        for start_i in range(0, len(df_ret) - L + 1):\n",
    "            end_i = start_i + L - 1\n",
    "            r_bh = df_ret[\"spx_ret_next\"].iloc[start_i : end_i + 1].to_numpy()\n",
    "            r_ls = df_ret[\"strategy_ret\"].iloc[start_i : end_i + 1].to_numpy()\n",
    "\n",
    "            W_bh = evolve_with_daily_contribution(r_bh, contrib=contrib)\n",
    "            W_ls = evolve_with_daily_contribution(r_ls, contrib=contrib)\n",
    "\n",
    "            out.append(\n",
    "                {\n",
    "                    \"start\": start_i,\n",
    "                    \"end\": end_i,\n",
    "                    \"days\": L,\n",
    "                    \"final_bh\": float(W_bh[-1]),\n",
    "                    \"final_ls\": float(W_ls[-1]),\n",
    "                    \"mult_bh\": contribution_multiple(W_bh[-1], contrib, L),\n",
    "                    \"mult_ls\": contribution_multiple(W_ls[-1], contrib, L),\n",
    "                    \"sharpe_bh\": approx_sharpe(r_bh),\n",
    "                    \"sharpe_ls\": approx_sharpe(r_ls),\n",
    "                    \"mdd_bh\": max_drawdown(W_bh),\n",
    "                    \"mdd_ls\": max_drawdown(W_ls),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) 5Y block bootstrap Monte Carlo\n",
    "# ============================================================\n",
    "def bootstrap_5y_blocks(\n",
    "    df_ret: pd.DataFrame,\n",
    "    n_sims: int = 5000,\n",
    "    block_years: int = 5,\n",
    "    contrib: float = 10.0,\n",
    "    seed: int = 123,\n",
    ") -> pd.DataFrame:\n",
    "    windows = rolling_windows_5y(df_ret, block_years=block_years, contrib=contrib)\n",
    "    if windows.empty:\n",
    "        raise ValueError(\"No valid 5-year windows found. Check data length and dates.\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    sampled_idx = rng.integers(0, len(windows), size=n_sims)\n",
    "    sim = windows.iloc[sampled_idx].copy().reset_index(drop=True)\n",
    "\n",
    "    sim[\"sim\"] = np.arange(n_sims)\n",
    "    sim[\"ls_minus_bh\"] = sim[\"final_ls\"] - sim[\"final_bh\"]\n",
    "    sim[\"ls_over_bh\"] = sim[\"final_ls\"] / (sim[\"final_bh\"] + 1e-12)\n",
    "    return sim\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) Plot helpers\n",
    "# ============================================================\n",
    "def plot_wealth_paths(df_ret: pd.DataFrame, W_bh: np.ndarray, W_ls: np.ndarray, outpath: Path) -> None:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = pd.to_datetime(df_ret[\"Date\"], errors=\"coerce\")\n",
    "    if x.isna().all():\n",
    "        x = np.arange(len(df_ret))\n",
    "\n",
    "    plt.plot(x, W_bh[1:], label=\"Buy & Hold (daily $10)\", color=\"steelblue\")\n",
    "    plt.plot(x, W_ls[1:], label=\"Long/Short LSTM (daily $10)\", color=\"tomato\", alpha=0.9)\n",
    "    plt.title(\"Wealth Paths with Daily $10 Contributions\")\n",
    "    plt.ylabel(\"Portfolio Value ($)\")\n",
    "    plt.xlabel(\"Date\" if not isinstance(x, np.ndarray) else \"Index\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_mc_distribution(mc5: pd.DataFrame, out1: Path, out2: Path) -> None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.hist(mc5[\"final_bh\"], bins=60, alpha=0.55, label=\"BH final wealth (5y)\", color=\"steelblue\")\n",
    "    plt.hist(mc5[\"final_ls\"], bins=60, alpha=0.55, label=\"LS final wealth (5y)\", color=\"tomato\")\n",
    "    plt.title(\"5-Year Block Bootstrap: Distribution of Final Wealth\")\n",
    "    plt.xlabel(\"Final wealth over 5y ($, daily $10 contributions)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out1, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.hist(mc5[\"ls_minus_bh\"], bins=80, alpha=0.9, color=\"purple\")\n",
    "    plt.axvline(0, color=\"black\", linewidth=2)\n",
    "    plt.title(\"5-Year Block Bootstrap: (LS - BH) Final Wealth\")\n",
    "    plt.xlabel(\"Final wealth difference ($)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out2, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) Main\n",
    "# ============================================================\n",
    "def main() -> None:\n",
    "    set_seeds(42)\n",
    "\n",
    "    # ---- Load ----\n",
    "    price = load_price_file(\"spx.csv\")\n",
    "\n",
    "    # ---- Walk-forward LSTM OOS strategy returns ----\n",
    "    cfg = WalkForwardConfig(\n",
    "        lookback=60,\n",
    "        initial_train_years=10,\n",
    "        retrain_every_days=252 * 5,\n",
    "        epochs=8,\n",
    "        batch_size=256,\n",
    "        patience=3,\n",
    "        val_frac=0.2,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    df_ret = walk_forward_oos_returns(\n",
    "        price_df=price,\n",
    "        cfg=cfg,\n",
    "        transaction_cost_bps=3,\n",
    "        slippage_bps=2,\n",
    "    )\n",
    "\n",
    "    outdir = Path(\".\")\n",
    "    df_ret.to_csv(outdir / \"oos_daily_returns.csv\", index=False)\n",
    "\n",
    "    # ---- Full-period analytics (daily $10 contributions) ----\n",
    "    contrib = 10.0\n",
    "    r_bh = df_ret[\"spx_ret_next\"].to_numpy(dtype=float)\n",
    "    r_ls = df_ret[\"strategy_ret\"].to_numpy(dtype=float)\n",
    "\n",
    "    W_bh = evolve_with_daily_contribution(r_bh, contrib=contrib)\n",
    "    W_ls = evolve_with_daily_contribution(r_ls, contrib=contrib)\n",
    "\n",
    "    summary = {\n",
    "        \"days_traded\": len(df_ret),\n",
    "        \"period_start\": df_ret[\"Date\"].iloc[0],\n",
    "        \"period_end\": df_ret[\"Date\"].iloc[-1],\n",
    "        \"final_wealth_bh\": float(W_bh[-1]),\n",
    "        \"final_wealth_ls\": float(W_ls[-1]),\n",
    "        \"contrib_multiple_bh\": contribution_multiple(W_bh[-1], contrib, len(df_ret)),\n",
    "        \"contrib_multiple_ls\": contribution_multiple(W_ls[-1], contrib, len(df_ret)),\n",
    "        \"sharpe_bh_approx\": approx_sharpe(r_bh),\n",
    "        \"sharpe_ls_approx\": approx_sharpe(r_ls),\n",
    "        \"max_drawdown_bh\": max_drawdown(W_bh),\n",
    "        \"max_drawdown_ls\": max_drawdown(W_ls),\n",
    "    }\n",
    "\n",
    "    # XIRR only if dates are real\n",
    "    try:\n",
    "        pd.to_datetime(df_ret[\"Date\"])\n",
    "        summary[\"xirr_bh\"] = xirr_daily(df_ret[\"Date\"], contrib=contrib, ending_wealth=W_bh[-1])\n",
    "        summary[\"xirr_ls\"] = xirr_daily(df_ret[\"Date\"], contrib=contrib, ending_wealth=W_ls[-1])\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n=== Full-period descriptive summary (daily $10 contributions) ===\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    (outdir / \"summary_full_period.txt\").write_text(\n",
    "        \"\\n\".join([f\"{k}: {v}\" for k, v in summary.items()]) + \"\\n\",\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    wealth_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Date\": df_ret[\"Date\"],\n",
    "            \"wealth_bh\": W_bh[1:],\n",
    "            \"wealth_ls\": W_ls[1:],\n",
    "        }\n",
    "    )\n",
    "    wealth_df.to_csv(outdir / \"wealth_paths_full_period.csv\", index=False)\n",
    "\n",
    "    plot_wealth_paths(df_ret, W_bh, W_ls, outdir / \"figure_wealth_paths.png\")\n",
    "\n",
    "    # ---- Rolling 5-year windows ----\n",
    "    roll5 = rolling_windows_5y(df_ret, block_years=5, contrib=contrib)\n",
    "    roll5.to_csv(outdir / \"rolling_5y_metrics.csv\", index=False)\n",
    "    print(f\"\\nComputed {len(roll5)} rolling 5-year windows -> rolling_5y_metrics.csv\")\n",
    "\n",
    "    # ---- 5-year block bootstrap Monte Carlo ----\n",
    "    mc5 = bootstrap_5y_blocks(df_ret, n_sims=5000, block_years=5, contrib=contrib, seed=123)\n",
    "    mc5.to_csv(outdir / \"mc_5y_block_bootstrap.csv\", index=False)\n",
    "\n",
    "    p_win = float(np.mean(mc5[\"final_ls\"] > mc5[\"final_bh\"]))\n",
    "    print(\"\\n=== 5-year block bootstrap MC summary ===\")\n",
    "    print(f\"P(LS beats BH over a random 5y block): {p_win:.3f}\")\n",
    "    print(f\"Median LS/BH: {np.median(mc5['ls_over_bh']):.3f}\")\n",
    "    print(f\"Median (LS - BH) wealth: {np.median(mc5['ls_minus_bh']):.2f}\")\n",
    "    print(\n",
    "        \"5th/95th pct (LS - BH): \"\n",
    "        f\"{np.quantile(mc5['ls_minus_bh'], 0.05):.2f} / {np.quantile(mc5['ls_minus_bh'], 0.95):.2f}\"\n",
    "    )\n",
    "\n",
    "    plot_mc_distribution(\n",
    "        mc5,\n",
    "        outdir / \"figure_mc5_final_wealth.png\",\n",
    "        outdir / \"figure_mc5_ls_minus_bh.png\",\n",
    "    )\n",
    "\n",
    "    print(\"\\nOutputs written:\")\n",
    "    for f in [\n",
    "        \"oos_daily_returns.csv\",\n",
    "        \"wealth_paths_full_period.csv\",\n",
    "        \"rolling_5y_metrics.csv\",\n",
    "        \"mc_5y_block_bootstrap.csv\",\n",
    "        \"summary_full_period.txt\",\n",
    "        \"figure_wealth_paths.png\",\n",
    "        \"figure_mc5_final_wealth.png\",\n",
    "        \"figure_mc5_ls_minus_bh.png\",\n",
    "    ]:\n",
    "        print(f\"- {f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7cd7b-1039-442b-bb8d-547b04ba4af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
